{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RDGopal/IB9CW0-Text-Analytics/blob/main/day_eight_rag_query_modes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXV5yBDPm2uf"
      },
      "source": [
        "# RAG with Llama Index: Query modes\n",
        "In this tutorial we will compare different query modes in LlamaIndex to see how they impact results. We will need to start with some installs again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BMEGxvmgt3O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install Ollama v0.1.30\n",
        "!curl https://ollama.ai/install.sh | sed 's#https://ollama.ai/download#https://github.com/jmorganca/ollama/releases/download/v0.1.30#' | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63m9Tah6hU0a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Setup the model as a global variable\n",
        "OLLAMA_MODEL='phi:latest'\n",
        "\n",
        "# Add the model to the environment of the operating system\n",
        "import os\n",
        "os.environ['OLLAMA_MODEL'] = OLLAMA_MODEL\n",
        "!echo $OLLAMA_MODEL # print the global variable to check it saved\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start ollama on the server (\"serve\")\n",
        "command = \"nohup ollama serve&\" # \"nohup\" and \"&\" means run in the background\n",
        "\n",
        "# Use subprocess.Popen to run the command\n",
        "process = subprocess.Popen(command,\n",
        "                            shell=True,\n",
        "                            stdout=subprocess.PIPE,\n",
        "                            stderr=subprocess.PIPE)\n",
        "\n",
        "time.sleep(5)  # Makes Python wait for 5 seconds\n",
        "\n",
        "# Install prerequisites\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-llms-ollama\n",
        "!pip install llama-index ipywidgets\n",
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama_index.readers.web\n",
        "!pip install llama-index-vector-stores-chroma\n",
        "!pip install chromadb\n",
        "\n",
        "# Import required modules from the llama_index library\n",
        "from llama_index.core import VectorStoreIndex, SummaryIndex, SimpleDirectoryReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "# Import ChromaVectorStore and chromadb module\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import chromadb\n",
        "\n",
        "# Import the Ollama class\n",
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "# Use the global variable (OLLAMA_MODEL) as our LLM\n",
        "# Set a timeout of 8 minutes in case of CPU\n",
        "llm = Ollama(model=OLLAMA_MODEL, request_timeout=480.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fxTuV8TJs4l"
      },
      "outputs": [],
      "source": [
        "# Query the model via the command line\n",
        "# First time running it will \"pull\" (import) the model\n",
        "!ollama run $OLLAMA_MODEL \"Tell me a joke\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3QKoFw9-AcA"
      },
      "source": [
        "We have a generator but now we needed a retriever to augment our results. Here we will extract some data from a webpage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrvUwb8oj-9x"
      },
      "outputs": [],
      "source": [
        "# Initialize a HuggingFace Embedding model\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "# Specify the LLM and embedding model into LlamaIndex's settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ERgcxIF6kHo",
        "outputId": "369511ca-61c8-4b71-f9b2-c5472d0cd7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text\n",
            "Warwick Business School launches £3m Gillmore Centre for Financial TechnologyContactSign upPrivacySearch ...   Toggle NavigationHomeAuto financeFleet financeEquipment financeMarket DataRegulationTechnologyPeopleJobsWhite Papers InnovationDigitalisationDigital events  Warwick Business School launches £3m Gillmore Centre for Financial Technology{JLinkedShare} Written by Lisa Laverick Published: 28 July 2023Created: 28 July 2023Warwick Business School has launched the Gillmore Centre for Financial Technology, backed by £3 million funding, to spearhead cutting-edge research and innovation for the UK’s financial and technology sectors.The new Centre will deliver GillmoreGPT, a unique index of FinTech research, a Crypto Index that tracks all crypto prices charted against inflation, mobile and platform based fintech solutions, immersive technologies for financial literacy, as well as leading research on AI development, machine learning and fraud.Minister for tech and the digital economy, Paul Scully MP, said: “The UK is the second largest global centre for FinTech, and this new facility will serve as an incubator for a new generation of businesses and a leading hub for the latest academic research and insights.”The Centre will be led by 25 academics and FinTech business leaders who will drive research and development across its specialisms. The Centre has further plans to hire a number of top research fellows by the end of the year to continue expanding its expertise.Academics Moris Strub, an expert in financial engineering, and Michael Mortenson, an expert in cloud computing and data analytics, have joined the Centre to add to its expertise.They will team up with Crypto expert Amit Choudhary, ex-Polygon Labs and Co-Founder of web 3.0 product developer ChainSolid Labs, and former Nationwide financial risk and regulation expert John Curtis, who joined the Gillmore Centre of Financial Technology as research fellows.The Centre will also act as a platform for industry collaboration projects, virtual and augmented reality teaching, and applications of advanced generative AI in financial services.The lab area features state-of-the-art computing facilities, advanced wall screens, virtual reality capabilities, as well as access to AI and data analytics software.Ram Gopal, Director of the Gillmore Centre for Financial Technology (pictured), said: “The launch of the Gillmore Centre for Financial Technology is a landmark moment for academia and the financial and technology industries, initiating a huge growth drive for UK R&D. We’ve seen over recent months the rapid development of emerging technologies, while the evolving economic situation requires innovative thinking and world-class research pioneers to shape the UK’s growth path, which is what we’re here to provide.“The Gillmore Centre for Financial Technology will act as a beacon for industry leading research across fields such as AI, blockchain and machine learning, helping to elevate government policy, inform regulators, and guide businesses through the safe development of these areas.“The UK is primed to become a global hub for financial technology and the Centre closely aligns with the government’s aims of becoming a science and technology superpower.”The Gillmore Centre for Financial Technology has been set up following a £3 million donation from Clive Gillmore, an alumnus of Warwick University and CEO and Group CIO of Mondrian Investment Partners. Latest stories FCA, FOS: differing approaches to DCA FCA, FOS: differing approaches to DCA Alfa to sponsor the AFC Outstanding Achievement Award 2024 Alfa to sponsor the AFC Outstanding Achievement Award 2024 Mach Recruitment receives £45m invoice finance facility from Metro Bank Mach Recruitment receives £45m invoice finance facility from Metro Bank Paragon Bank’s SME Lending division appoints Adam Zadora as Business Development Director Paragon Bank’s SME Lending division appoints Adam Zadora as Business Development Director Back to Top© 2024 Asset Finance International\n"
          ]
        }
      ],
      "source": [
        "from llama_index.readers.web import BeautifulSoupWebReader\n",
        "\n",
        "# web page\n",
        "url = \"https://www.assetfinanceinternational.com/index.php/technology/technology-archive/technology-articles/22703-warwick-business-school-launches-3m-gillmore-centre-for-financial-technology\"\n",
        "\n",
        "# use BeautifulSoup to parse the HTML data\n",
        "documents = BeautifulSoupWebReader().load_data([url])\n",
        "documents = documents[0].text\n",
        "\n",
        "# replace \"\\n\" (paragraph break) and \"\\t\" (tab character)\n",
        "documents = documents.replace(\"\\n\", \"\")\n",
        "documents = documents.replace(\"\\t\", \"\")\n",
        "\n",
        "# print to screen\n",
        "print(\"Cleaned text\")\n",
        "print(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will use a basic version of chunking - no LlamaIndex - to split the documents based on full stops with spaces after them. After splitting we'll write each document to disk storage:"
      ],
      "metadata": {
        "id": "Be6iB9Olynr7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8Yk-Rd2k-1O"
      },
      "outputs": [],
      "source": [
        "split_docs = documents.split(\". \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqdbBeF0WajZ"
      },
      "outputs": [],
      "source": [
        "!mkdir -p '/content/data/' # create an empty directory called \"data\"\n",
        "\n",
        "count = 0\n",
        "\n",
        "for doc in split_docs: # iterate through the results\n",
        "  fname = \"/content/data/Output\" + str(count) + \".txt\"\n",
        "  with open(fname, \"w\") as text_file:\n",
        "    text_file.write(doc) # save the file\n",
        "  count += 1 # increment the count"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, we can save this in a vector database:"
      ],
      "metadata": {
        "id": "HI3jGGt6y3cD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il1-SbLWW-YJ",
        "outputId": "856b168c-5a6a-47f6-947b-62e76dcfb50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5 docs\n",
            "name='another-day-another-demo' id=UUID('986ece56-109d-4175-a623-2a899495c32a') metadata=None tenant='default_tenant' database='default_database'\n",
            "Collection name is: another-day-another-demo\n"
          ]
        }
      ],
      "source": [
        "# Import ChromaVectorStore and chromadb module\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import chromadb\n",
        "\n",
        "# Load documents\n",
        "reader = SimpleDirectoryReader(\"/content/data\") # load documents from the /data folder\n",
        "docs = reader.load_data()\n",
        "print(f\"Loaded {len(docs)} docs\")\n",
        "\n",
        "# Create client (\"db\") and a database (\"chroma_db\")\n",
        "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# Create a collection/table (\"demo-for-ram\") in the db\n",
        "chroma_collection = db.create_collection(\"another-day-another-demo\")\n",
        "\n",
        "# Set up ChromaVectorStore and load in data\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "# Specify Chroma as our vector db\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# Create the vector index\n",
        "vector_index = VectorStoreIndex.from_documents(\n",
        "    docs, # the file created earlier\n",
        "    storage_context = storage_context,\n",
        "    embed_model = embed_model\n",
        ")\n",
        "\n",
        "# Print the metadata\n",
        "print(chroma_collection)\n",
        "\n",
        "# Print the name of the collection (table)\n",
        "print(f'Collection name is: {chroma_collection.name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDR29uuFXJuB"
      },
      "source": [
        "## Compact Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "l8YgzCIOGo1f",
        "outputId": "838322b2-6bae-4292-b79d-96f3432504fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The Gillmore Centre has received a funding of $3 million to spearhead cutting-edge research and innovation for the UK's financial and technology sectors.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"compact\")\n",
        "\n",
        "response = query_engine.query(\"How much was invested in the Gillmore Centre?\")\n",
        "\n",
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xSEosf-ZrLB"
      },
      "source": [
        "## Refine Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "IZJQGHabZref",
        "outputId": "7aea0828-ba24-48ba-b0ed-da973aaa80e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" In the context of funding allocation for the Gillmore Centre's research on AI (A), machine learning (M), and fraud detection (F), we can say that $8 million will be allocated to AI development and  $4 million each for machine learning and fraud detection, given that the total budget is set at $12 million. This solution adheres to the conditions provided in the puzzle, demonstrating a direct proof. It also shows how inductive logic is used when forming hypotheses based on existing data (AI's funding being twice of Fraud Detection) to reach conclusions about new situations (allocation of funds). The tree of thought reasoning is also evident in this problem as each decision leads to subsequent decisions until the final allocation is achieved.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"refine\")\n",
        "\n",
        "response = query_engine.query(\"How much was invested in the Gillmore Centre?\")\n",
        "\n",
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "811igULaZ1Qv"
      },
      "source": [
        "## Tree Summarise Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9k_Jkc-nZ1a3",
        "outputId": "6a35a8cb-b9de-47d0-b1c8-80f7978bae7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The Gillmore Centre was launched with a funding of £3 million.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"tree_summarize\")\n",
        "\n",
        "response = query_engine.query(\"How much was invested in the Gillmore Centre?\")\n",
        "\n",
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiZ_k1fmaAe5"
      },
      "source": [
        "## Comparison with a Different Type of Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gO0F1FB4lioy",
        "outputId": "9e81a633-6647-4bbb-eb4a-9403bb0d2b96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' It is difficult to determine who would know the most about cloud-based analytics without additional context or information. However, based on the given context information, it seems that the Centre has plans to hire a number of top research fellows by the end of the year to expand its expertise in financial technology, which includes cloud computing and data analytics. The Centre also features state-of-the-art computing facilities with advanced wall screens and virtual reality capabilities, as well as access to AI and data analytics software. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"compact\")\n",
        "\n",
        "response = query_engine.query(\"Who would know most about cloud-based analytics?\")\n",
        "\n",
        "response.response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "iWY4fQqWlrAv",
        "outputId": "c3f241f7-75e9-4bad-fcaa-8777e6a2f6e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The answer can vary depending on the context and additional information provided. If Michael Mortenson has published papers or presented at conferences on cloud computing and data analytics, then he would have more expertise in this area compared to Amit Choudhary who specializes in machine learning but not necessarily cloud-based analytics. However, if both of them have similar areas of research and experience, then they could be considered as equally knowledgeable in cloud-based analytics. Without any specific information about their respective fields of research and experience, it is difficult to determine who would know the most about cloud-based analytics.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"refine\")\n",
        "\n",
        "response = query_engine.query(\"Who would know most about cloud-based analytics?\")\n",
        "\n",
        "response.response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "antjpaEGlvwN",
        "outputId": "19e1915e-6240-4362-b95d-41f97f67c726"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Michael Mortenson, an expert in cloud computing and data analytics who has joined the Gillmore Centre as a research fellow, would be the best resource for information on cloud-based analytics.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"tree_summarize\")\n",
        "\n",
        "response = query_engine.query(\"Who would know most about cloud-based analytics?\")\n",
        "\n",
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, lets check which documents were used in the last generation:"
      ],
      "metadata": {
        "id": "Zo_Mb2IdzOMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ1diUGgC2y-",
        "outputId": "4e052b09-2f97-4b93-aff0-8f4452bfa4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'5ae52443-43b4-4f45-bfb2-7e4379f53241': {'file_path': '/content/data/Output2.txt',\n",
              "  'file_name': 'Output2.txt',\n",
              "  'file_type': 'text/plain',\n",
              "  'file_size': 1199,\n",
              "  'creation_date': '2024-05-06',\n",
              "  'last_modified_date': '2024-05-06'},\n",
              " '24974fff-1b82-427c-a5a2-985b9240cac5': {'file_path': '/content/data/Output3.txt',\n",
              "  'file_name': 'Output3.txt',\n",
              "  'file_type': 'text/plain',\n",
              "  'file_size': 911,\n",
              "  'creation_date': '2024-05-06',\n",
              "  'last_modified_date': '2024-05-06'}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bknBVWE_zY6"
      },
      "source": [
        "And that's it! Well done 👍"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}